"""
æ­¯ç§‘ã‚¯ãƒªãƒ‹ãƒƒã‚¯å…¬é–‹å‰ãƒã‚§ãƒƒã‚¯ãƒ„ãƒ¼ãƒ« - Streamlit UI

Phase 1: ãƒªãƒ³ã‚¯åˆ‡ã‚Œã€é›»è©±ç•ªå·ã€èª¤å­—è„±å­—ã®3ã¤ã®ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½
"""

import streamlit as st
import yaml
from pathlib import Path
from typing import List, Dict, Tuple, Optional

from utils.crawler import WebCrawler
from utils.reporter import ExcelReporter
from utils.excel_handler import ExcelHandler
from checkers import LinkChecker, PhoneChecker, UnifiedAIChecker


def load_config():
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
    config_path = Path(__file__).parent / "config.yaml"
    with open(config_path, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)


def main():
    """ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³"""
    
    # ãƒšãƒ¼ã‚¸è¨­å®š
    st.set_page_config(
        page_title="ã‚¯ãƒªãƒ‹ãƒƒã‚¯å…¬é–‹å‰ãƒã‚§ãƒƒã‚¯",
        page_icon="ğŸ“‹",
        layout="centered"
    )
    
    # èƒŒæ™¯ç”»åƒã‚’èª­ã¿è¾¼ã¿ï¼ˆBase64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ï¼‰
    import base64
    def get_base64_image(image_path):
        with open(image_path, "rb") as img_file:
            return base64.b64encode(img_file.read()).decode()

    try:
        bg_image = get_base64_image("dog.png")
        st.markdown(f"""
            <style>
            .stApp {{
                background-image: url("data:image/png;base64,{bg_image}");
                background-size: contain;
                background-position: center;
                background-repeat: no-repeat;
                background-attachment: fixed;
            }}
            .main > div {{
                background-color: rgba(255, 255, 255, 0.9);
                padding: 2rem;
                border-radius: 10px;
                box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            }}
            </style>
        """, unsafe_allow_html=True)
    except Exception:
        pass
    
    # ã‚¿ã‚¤ãƒˆãƒ«
    st.title("ğŸ“‹ ã‚¯ãƒªãƒ‹ãƒƒã‚¯å…¬é–‹å‰ãƒã‚§ãƒƒã‚¯")
    st.sidebar.caption("æœ€çµ‚æ›´æ–°: 2026/02/15 13:16")
    
    # HTMLã® lang å±æ€§ã‚’ ja ã«å¤‰æ›´ (SEO/ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£å¯¾å¿œ)
    # Streamlitã®View Sourceã§ã¯ en ã®ã¾ã¾ã«è¦‹ãˆã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ãŒã€ãƒ–ãƒ©ã‚¦ã‚¶ã®DOMä¸Šã§ã¯ ja ã«æ›¸ãæ›ã‚ã‚Šã¾ã™ã€‚
    st.markdown(
        """
        <script>
        const observer = new MutationObserver(function(mutations) {
            var html = window.parent.document.getElementsByTagName('html')[0];
            if (html.getAttribute('lang') !== 'ja') {
                html.setAttribute('lang', 'ja');
            }
        });
        observer.observe(window.parent.document.documentElement, { attributes: true });
        // åˆå›å®Ÿè¡Œ
        window.parent.document.getElementsByTagName('html')[0].setAttribute('lang', 'ja');
        </script>
        """,
        unsafe_allow_html=True
    )
    st.markdown("---")
    
    # è¨­å®šèª­ã¿è¾¼ã¿
    config = load_config()

    # Basicèªè¨¼è¨­å®šï¼ˆSecretsã‹ã‚‰å–å¾—ã€UIã«ã¯è¡¨ç¤ºã—ãªã„ï¼‰
    try:
        auth_id = st.secrets.get("BASIC_AUTH_ID", "")
        auth_pass = st.secrets.get("BASIC_AUTH_PASS", "")
    except Exception:
        auth_id = ""
        auth_pass = ""
    
    # Excelãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    st.subheader("ğŸ“ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ­ãƒ¼ãƒ‰")
    uploaded_file = st.file_uploader(
        "DC-config.xlsxã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
        type=["xlsx"],
        help="ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ãƒ—ãƒ©ãƒ³ç”¨ã®æƒ…å ±ã‚’åŒæœŸã—ã€ãƒã‚§ãƒƒã‚¯å¯¾è±¡ã‚’å–å¾—ã—ã¾ã™"
    )

    url = ""
    clinic_name = ""
    correct_phone = ""

    if uploaded_file:
        # ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜
        temp_path = "DC-config.xlsx"
        with open(temp_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        # Excelæ“ä½œ
        handler = ExcelHandler(temp_path)
        if handler.load():
            with st.spinner("ã‚·ãƒ¼ãƒˆé–“ã‚’åŒæœŸã—ã¦ã„ã¾ã™..."):
                handler.sync_sheets()
            
            # æƒ…å ±å–å¾—
            url, clinic_name, correct_phone = handler.get_basic_info()
            
            if url and clinic_name:
                st.success(f"âœ… è¨­å®šã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: **{clinic_name}**")
                
                # å–å¾—æƒ…å ±ã®ç¢ºèªç”¨è¡¨ç¤º
                col1, col2 = st.columns(2)
                with col1:
                    st.info(f"ğŸŒ **URL**: {url}")
                with col2:
                    st.info(f"ğŸ“ **é›»è©±**: {correct_phone}")
                
                # --- URLãƒªã‚¹ãƒˆã®è‡ªå‹•åé›†ã¨è¡¨ç¤º ---
                if "target_urls" not in st.session_state or st.session_state.get("last_uploaded_url") != url:
                    with st.spinner("å‡¦ç†å¯¾è±¡ã®URLã‚’æŠ½å‡ºã—ã¦ã„ã¾ã™..."):
                        pre_crawler = WebCrawler(config)
                        if auth_id and auth_pass:
                            pre_crawler.set_auth(auth_id, auth_pass)
                        pages = pre_crawler.crawl_site(url)
                        st.session_state.target_urls = "\n".join(pages.keys())
                        st.session_state.last_uploaded_url = url

                st.markdown("---")
                st.markdown("**ã€å‡¦ç†å¯¾è±¡ã®URLä¸€è¦§ã€‘ä¸å‚™ãŒã‚ã‚Œã°æ­£ã—ã„URLãƒªã‚¹ãƒˆã‚’ã‚»ãƒƒãƒˆã—ã¦ä¸‹ã•ã„ã€‚**")
                target_urls_input = st.text_area(
                    "URLãƒªã‚¹ãƒˆå…¥åŠ›æ¬„",
                    value=st.session_state.target_urls,
                    height=200,
                    label_visibility="collapsed",
                    key="url_editor"
                )
                st.session_state.target_urls = target_urls_input

                # ãƒã‚§ãƒƒã‚¯é–‹å§‹ãƒœã‚¿ãƒ³ï¼ˆãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã®ä¸‹ã«é…ç½®ï¼‰
                if st.button("ğŸš€ ãƒã‚§ãƒƒã‚¯é–‹å§‹", type="primary", use_container_width=True):
                    # å…¥åŠ›ãƒã‚§ãƒƒã‚¯
                    url_list = [u.strip() for u in st.session_state.target_urls.split("\n") if u.strip()]
                    if not url_list or not clinic_name:
                        st.error("âŒ åŒ»é™¢åã¨å‡¦ç†å¯¾è±¡ã®URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                    else:
                        # è¨­å®šã‚’æ›´æ–°
                        if correct_phone:
                            if "checks" not in config:
                                config["checks"] = {}
                            if "phone_check" not in config["checks"]:
                                config["checks"]["phone_check"] = {}
                            config["checks"]["phone_check"]["correct_phone"] = correct_phone
                        
                        # ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
                        try:
                            with st.spinner("ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œä¸­..."):
                                # NGè¡¨ç¾ãƒ«ãƒ¼ãƒ«ã‚’Excelã‹ã‚‰å–å¾—
                                ng_rules = handler.get_ng_rules()
                                master_data = handler.get_all_master_data()
                                results, checked_urls, raw_pages = run_checks(url_list, config, auth_id, auth_pass, ng_rules=ng_rules, master_data=master_data)
                            
                            # çŠ¶æ…‹ã‚’ä¿å­˜
                            st.session_state.results = results
                            st.session_state.checked_urls = checked_urls
                            st.session_state.last_clinic_name = clinic_name
                            
                            # Excelãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
                            reporter = ExcelReporter(config)
                            st.session_state.excel_data = reporter.generate_report(clinic_name, results)
                            
                            # è¨ºæ–­ç”¨ç”Ÿãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
                            import io
                            import zipfile
                            zip_buffer = io.BytesIO()
                            with zipfile.ZipFile(zip_buffer, "a", zipfile.ZIP_DEFLATED, False) as zip_file:
                                for url, (content, soup) in raw_pages.items():
                                    # URLã‚’ãƒ•ã‚¡ã‚¤ãƒ«åã«å®‰å…¨ãªå½¢å¼ã«å¤‰æ›
                                    safe_filename = url.replace("https://", "").replace("http://", "").replace("/", "_").replace(":", "_") + ".txt"
                                    zip_file.writestr(safe_filename, content)
                            st.session_state.debug_txt_zip = zip_buffer.getvalue()
                            
                            st.success("âœ… ãƒã‚§ãƒƒã‚¯å®Œäº†ï¼")
                        except Exception as e:
                            st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                            st.exception(e)
            else:
                st.warning("âš ï¸ Excelå†…ã‹ã‚‰URLã¾ãŸã¯åŒ»é™¢åãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        st.info("ğŸ’¡ ã¾ãšã¯ DC-config.xlsx ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")

    # session_stateã®åˆæœŸåŒ–
    if "results" not in st.session_state:
        st.session_state.results = None
    if "checked_urls" not in st.session_state:
        st.session_state.checked_urls = None
    if "excel_data" not in st.session_state:
        st.session_state.excel_data = None
    if "last_clinic_name" not in st.session_state:
        st.session_state.last_clinic_name = None
    if "debug_txt_zip" not in st.session_state:
        st.session_state.debug_txt_zip = None

    # ãƒã‚§ãƒƒã‚¯çµæœãŒè¡¨ç¤ºå¯èƒ½ãªå ´åˆã«è¡¨ç¤ºï¼ˆãƒœã‚¿ãƒ³ã®å¤–å´ã«é…ç½®ã—ã¦æ°¸ç¶šåŒ–ï¼‰
    if st.session_state.results and st.session_state.checked_urls:
        st.markdown("---")
        st.subheader("ğŸ“Š ãƒã‚§ãƒƒã‚¯çµæœã‚µãƒãƒªãƒ¼")
        
        # ãƒã‚§ãƒƒã‚¯ã—ãŸURLä¸€è¦§ã‚’è¡¨ç¤º
        st.markdown("""
            <div style="background-color: #d4edda; padding: 1rem; border-radius: 5px; margin-bottom: 1rem;">
                <strong>ãƒã‚§ãƒƒã‚¯ã—ãŸãƒšãƒ¼ã‚¸:</strong><br>
                {}
            </div>
        """.format("<br>".join(st.session_state.checked_urls)), unsafe_allow_html=True)
        
        ok_count = sum(1 for r in st.session_state.results if r["status"] == "ok")
        warning_count = sum(1 for r in st.session_state.results if r["status"] == "warning")
        error_count = sum(1 for r in st.session_state.results if r["status"] == "error")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("âœ… OK", ok_count)
        with col2:
            st.metric("âš ï¸ è­¦å‘Š", warning_count)
        with col3:
            st.metric("âŒ ã‚¨ãƒ©ãƒ¼", error_count)
        
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
        if st.session_state.excel_data:
            st.download_button(
                label="ğŸ“¥ çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (Excel)",
                data=st.session_state.excel_data,
                file_name=f"{st.session_state.last_clinic_name}ãƒã‚§ãƒƒã‚¯çµæœ.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True
            )
            
        # è¨ºæ–­ç”¨ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        if st.session_state.debug_txt_zip:
            with st.expander("ğŸ” èª¿æŸ»ãƒ»è¨ºæ–­ç”¨ (ãƒ—ãƒ­ã‚°ãƒ©ãƒ ãŒèª­ã¿å–ã£ãŸç”Ÿãƒ‡ãƒ¼ã‚¿)"):
                st.info("AIãŒã€Œæ–‡ç« ãŒé€”åˆ‡ã‚Œã¦ã„ã‚‹ã€ã¨èª¤èªã™ã‚‹å ´åˆã€ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦å†…å®¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                st.download_button(
                    label="ğŸ“„ èª­ã¿å–ã‚Šãƒ†ã‚­ã‚¹ãƒˆã‚’ä¸€æ‹¬ä¿å­˜ (ZIP)",
                    data=st.session_state.debug_txt_zip,
                    file_name=f"debug_raw_text_{st.session_state.last_clinic_name}.zip",
                    mime="application/zip",
                    use_container_width=True
                )


def run_checks(urls: List[str], config: dict, auth_id: str = "", auth_pass: str = "", ng_rules: Optional[List[dict]] = None, master_data: Optional[dict] = None):
    """
    ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ
    
    Args:
        urls: ãƒã‚§ãƒƒã‚¯å¯¾è±¡URLãƒªã‚¹ãƒˆ
        config: è¨­å®šè¾æ›¸
        auth_id: Basicèªè¨¼ID
        auth_pass: Basicèªè¨¼ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰
        ng_rules: NGè¡¨ç¾ãƒ«ãƒ¼ãƒ«ã®ãƒªã‚¹ãƒˆ
    
    Returns:
        (ãƒã‚§ãƒƒã‚¯çµæœã®ãƒªã‚¹ãƒˆ, ãƒã‚§ãƒƒã‚¯ã—ãŸURLã®ãƒªã‚¹ãƒˆ)
    """
    all_results = []
    
    # æ—¢å­˜ã®è¨­å®šã‚’ä¸Šæ›¸ãã—ãªã„ã‚ˆã†ã«ã‚³ãƒ”ãƒ¼
    run_config = config.copy()
    if ng_rules:
        run_config["ng_words_rules"] = ng_rules
    
    # Basicèªè¨¼æƒ…å ±
    auth = None
    if auth_id and auth_pass:
        auth = (auth_id, auth_pass)
    
    # ã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼åˆæœŸåŒ–
    crawler = WebCrawler(run_config)
    if auth:
        crawler.set_auth(auth_id, auth_pass)
    
    import concurrent.futures
    
    # ãƒšãƒ¼ã‚¸å–å¾—ã®ä¸¦åˆ—åŒ–
    pages = {}
    progress_text = st.empty()
    fetch_progress = st.progress(0)
    
    def fetch_single_page(url):
        return url, crawler.fetch_page(url)

    max_workers = run_config.get("crawler", {}).get("max_workers", 5)
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_url = {executor.submit(fetch_single_page, url): url for url in urls}
        for i, future in enumerate(concurrent.futures.as_completed(future_to_url)):
            url, result = future.result()
            if result:
                pages[url] = result
            progress_text.text(f"ãƒšãƒ¼ã‚¸ã®å†…å®¹ã‚’å–å¾—ä¸­ ({i+1}/{len(urls)}): {url}")
            fetch_progress.progress((i + 1) / len(urls))
    
    fetch_progress.empty()
    progress_text.empty()
    
    if not pages:
        st.error("å…¥åŠ›ã•ã‚ŒãŸURLã‹ã‚‰æœ‰åŠ¹ãªãƒšãƒ¼ã‚¸æƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        return [], []
    
    # ãƒã‚§ãƒƒã‚¯ã—ãŸURLã®ãƒªã‚¹ãƒˆ
    checked_urls = list(pages.keys())
    
    # ãƒã‚§ãƒƒã‚«ãƒ¼ã‚’åˆæœŸåŒ–ï¼ˆAIç³»ã¯ UnifiedAIChecker ã«çµ±åˆï¼‰
    checkers = [
        LinkChecker(run_config, auth=auth),
        PhoneChecker(run_config),
        UnifiedAIChecker(run_config, master_data=master_data, ng_rules=ng_rules)
    ]
    
    # å„ãƒšãƒ¼ã‚¸ã«å¯¾ã™ã‚‹ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œã®ä¸¦åˆ—åŒ–
    progress_bar = st.progress(0)
    total_tasks = len(pages)
    current_done = 0
    
    def run_all_checkers_for_page(page_url, page_data):
        page_content, soup = page_data
        page_results = []
        for checker in checkers:
            if checker.is_enabled():
                try:
                    res = checker.check(page_url, page_content, soup)
                    for r in res:
                        page_results.append(r.to_dict())
                except Exception as e:
                    print(f"ã‚¨ãƒ©ãƒ¼ ({checker.__class__.__name__} at {page_url}): {e}")
        return page_results

    # ãƒã‚§ãƒƒã‚¯ã®å®Ÿè¡Œ
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_page = {executor.submit(run_all_checkers_for_page, url, data): url for url, data in pages.items()}
        for future in concurrent.futures.as_completed(future_to_page):
            page_results = future.result()
            all_results.extend(page_results)
            current_done += 1
            progress_bar.progress(current_done / total_tasks)
    
    progress_bar.empty()
    
    return all_results, checked_urls, pages


if __name__ == "__main__":
    main()
